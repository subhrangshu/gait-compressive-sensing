{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQSi6a63CpvT"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from pywt import wavedec\n",
        "import pywt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import iqr\n",
        "import sys\n",
        "import copy\n",
        "from scipy.signal import detrend\n",
        "import copy\n",
        "import pdb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FS = 100 #define the sampling rate\n",
        "NUM_SAMPLES_BLOCK = 1000 #3000\n",
        "COEFF_LENGTHS = {'cA5': 39, 'cD5': 39, 'cD4': 70, 'cD3': 132, 'cD2': 256, 'cD1': 504} # Count length of wavedec coeff\n",
        "NUM_BITS_RUN_LEN = 4\n",
        "MAX_PRD = 0.4\n",
        "THRESH_PERC_APPROX = 0.999\n",
        "THRESH_PERC_D5 = 0.97\n",
        "THRESH_PERC_D4_D1 = 0.85"
      ],
      "metadata": {
        "id": "dYmLrQlAN9H4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wavelet_decomposition(sig):\n",
        "    cA5, cD5, cD4, cD3, cD2, cD1 = wavedec(sig, 'bior4.4', level=5)\n",
        "    coeffs = {'cA5': cA5, 'cD5': cD5, 'cD4': cD4, 'cD3': cD3, 'cD2': cD2, 'cD1': cD1}\n",
        "    print(len(coeffs['cA5']))\n",
        "    print(len(coeffs['cD5']))\n",
        "    print(len(coeffs['cD4']))\n",
        "    print(len(coeffs['cD3']))\n",
        "    print(len(coeffs['cD2']))\n",
        "    print(len(coeffs['cD1']))\n",
        "\n",
        "    #plot stuff\n",
        "    do_plot = False\n",
        "\n",
        "    if do_plot:\n",
        "        print('\\n\\n')\n",
        "        print('Plot of wavelet decomposition for all levels')\n",
        "        plt.subplots(figsize=(16,9))\n",
        "\n",
        "        plt.subplot(6,1,1)\n",
        "        plt.plot(coeffs['cA5'])\n",
        "        plt.title('cA5')\n",
        "\n",
        "        plt.subplot(6,1,2)\n",
        "        plt.plot(coeffs['cD5'])\n",
        "        plt.title('cD5')\n",
        "\n",
        "        plt.subplot(6,1,3)\n",
        "        plt.plot(coeffs['cD4'])\n",
        "        plt.title('cD4')\n",
        "\n",
        "        plt.subplot(6,1,4)\n",
        "        plt.plot(coeffs['cD3'])\n",
        "        plt.title('cD3')\n",
        "\n",
        "        plt.subplot(6,1,5)\n",
        "        plt.plot(coeffs['cD2'])\n",
        "        plt.title('cD2')\n",
        "\n",
        "        plt.subplot(6,1,6)\n",
        "        plt.plot(coeffs['cD1'])\n",
        "        plt.title('cD1')\n",
        "        plt.xlabel('Index')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('wavelet_decomposition.png', dpi=150)\n",
        "        plt.show()\n",
        "\n",
        "    return coeffs"
      ],
      "metadata": {
        "id": "CvTVtjMJOFV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wavelet_reconstruction(coeffs, orig_data, CR, do_plot=False):\n",
        "    reconstructed = pywt.waverec([coeffs['cA5'], coeffs['cD5'], coeffs['cD4'], coeffs['cD3'],\n",
        "                                    coeffs['cD2'], coeffs['cD1']], 'bior4.4')\n",
        "\n",
        "\n",
        "    if do_plot:\n",
        "        print('\\n\\n')\n",
        "        print('Plot of original signal through the process of compression and decompression:')\n",
        "\n",
        "        t = [i/FS for i in range(NUM_SAMPLES_BLOCK)]\n",
        "        plt.subplots(figsize=(6,4))\n",
        "        plt.plot(t, orig_data, label='Original Signal')\n",
        "        plt.plot(t, reconstructed, label='Reconstructed Signal')\n",
        "        plt.title('Compression Ratio: %.1f' % CR)\n",
        "        plt.xlabel('Time (seconds)  $\\longrightarrow$')\n",
        "        plt.ylabel('Amplitude $\\longrightarrow$')\n",
        "        plt.tight_layout()\n",
        "        plt.grid(True)\n",
        "        plt.legend(loc=1)\n",
        "        #axes = plt.gca()\n",
        "        #axes.set_xlim((17, 21.5))\n",
        "        plt.savefig('reconstructed.png', dpi=150)\n",
        "        plt.show()\n",
        "\n",
        "    return reconstructed"
      ],
      "metadata": {
        "id": "NGs_sop8OJLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def threshold_energy(coeffs, do_plot=False):\n",
        "    #make a deep copy of coeffs to retain the original version\n",
        "    coeffs_orig = copy.deepcopy(coeffs)\n",
        "\n",
        "    binary_map = {}\n",
        "    nonzero_coeff_count = {}\n",
        "\n",
        "    for key in coeffs.keys():\n",
        "        #sort the absolute value of the coefficients in descending order\n",
        "        tmp_coeffs = np.sort(np.abs(coeffs[key]))[::-1]\n",
        "\n",
        "        #calculate the threshold for retaining some percentage of the energy\n",
        "        if key == 'cA5':\n",
        "            thresh_perc = THRESH_PERC_APPROX\n",
        "        elif key == 'cD5':\n",
        "            thresh_perc = THRESH_PERC_D5\n",
        "        else:\n",
        "            thresh_perc = THRESH_PERC_D4_D1\n",
        "\n",
        "        energy_thresholded = thresh_perc*energy(tmp_coeffs)\n",
        "        energy_tmp = 0\n",
        "        for coeff in tmp_coeffs:\n",
        "            energy_tmp = energy_tmp + coeff**2\n",
        "\n",
        "            if energy_tmp >= energy_thresholded:\n",
        "                threshold = coeff\n",
        "                break\n",
        "\n",
        "        #set any coefficients below the threshold to zero\n",
        "        tmp_coeffs = coeffs[key]\n",
        "        inds_to_zero = np.where((tmp_coeffs < threshold) & (tmp_coeffs > -threshold))[0]\n",
        "        tmp_coeffs[inds_to_zero] = 0\n",
        "\n",
        "        #create the binary map\n",
        "        binary_map_tmp = np.ones(len(coeffs[key])).astype(int)\n",
        "        binary_map_tmp[inds_to_zero] = 0\n",
        "\n",
        "        #update the various dictionaries\n",
        "        coeffs[key] = tmp_coeffs\n",
        "        binary_map[key] = binary_map_tmp\n",
        "        nonzero_coeff_count[key] = len(tmp_coeffs)\n",
        "\n",
        "\n",
        "    if do_plot:\n",
        "        print('\\n\\n')\n",
        "        print('Plot of thresholded vs unthresholded coefficients:')\n",
        "        plt.subplots(figsize=(7,7))\n",
        "\n",
        "        plt.subplot(6,1,1)\n",
        "        plt.plot(coeffs_orig['cA5'], label='Org cA5')\n",
        "        plt.plot(coeffs['cA5'], label='Th cA5')\n",
        "        plt.grid(True)\n",
        "        plt.legend(loc=1)\n",
        "        #plt.title('cA5')\n",
        "\n",
        "        plt.subplot(6,1,2)\n",
        "        plt.plot(coeffs_orig['cD5'], label='Org cD5')\n",
        "        plt.plot(coeffs['cD5'], label='Th cD5')\n",
        "        plt.grid(True)\n",
        "        plt.legend(loc=1)\n",
        "        #plt.title('cD5')\n",
        "\n",
        "        plt.subplot(6,1,3)\n",
        "        plt.plot(coeffs_orig['cD4'], label='Org cD4')\n",
        "        plt.plot(coeffs['cD4'], label='Th cD4')\n",
        "        plt.ylabel('Amplitude $\\longrightarrow$')\n",
        "        plt.grid(True)\n",
        "        plt.legend(loc=1)\n",
        "        #plt.title('cD4')\n",
        "\n",
        "        plt.subplot(6,1,4)\n",
        "        plt.plot(coeffs_orig['cD3'], label='Org cD3')\n",
        "        plt.plot(coeffs['cD3'], label='Th cD3')\n",
        "        plt.grid(True)\n",
        "        plt.legend(loc=1)\n",
        "        #plt.title('cD3')\n",
        "\n",
        "        plt.subplot(6,1,5)\n",
        "        plt.plot(coeffs_orig['cD2'], label='Org cD2')\n",
        "        plt.plot(coeffs['cD2'], label='Th cD2')\n",
        "        plt.grid(True)\n",
        "        plt.legend(loc=1)\n",
        "        #plt.title('cD2')\n",
        "\n",
        "        plt.subplot(6,1,6)\n",
        "        plt.plot(coeffs_orig['cD1'], label='Org cD1')\n",
        "        plt.plot(coeffs['cD1'], label='Th cD1')\n",
        "        plt.grid(True)\n",
        "        plt.legend(loc=1)\n",
        "        plt.xlabel('Index $\\longrightarrow$')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.xlim(0,200)\n",
        "        plt.savefig('wavelet_thresholding.png', dpi=150)\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "    return coeffs, binary_map"
      ],
      "metadata": {
        "id": "gQ-uAj0eOMmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scale_coeffs(coeffs, do_plot=False):\n",
        "    coeffs_scaled = {}\n",
        "    scaling_factors = {}\n",
        "\n",
        "    for key in coeffs.keys():\n",
        "        shift_factor = np.min(coeffs[key])\n",
        "        coeffs_tmp = coeffs[key]-shift_factor\n",
        "\n",
        "        scale_factor = np.max(coeffs_tmp)\n",
        "        coeffs_tmp = coeffs_tmp/scale_factor\n",
        "\n",
        "        scaling_factors[key] = {'shift_factor': shift_factor, 'scale_factor': scale_factor}\n",
        "        coeffs_scaled[key] = coeffs_tmp\n",
        "\n",
        "\n",
        "    if do_plot:\n",
        "        print('\\n\\n')\n",
        "        print('Plot of scaled coefficients:')\n",
        "        plt.subplots(figsize=(16,9))\n",
        "\n",
        "        plt.subplot(6,1,1)\n",
        "        plt.plot(coeffs_scaled['cA5'])\n",
        "        plt.title('cA5')\n",
        "\n",
        "        plt.subplot(6,1,2)\n",
        "        plt.plot(coeffs_scaled['cD5'])\n",
        "        plt.title('cD5')\n",
        "\n",
        "        plt.subplot(6,1,3)\n",
        "        plt.plot(coeffs_scaled['cD4'])\n",
        "        plt.title('cD4')\n",
        "\n",
        "        plt.subplot(6,1,4)\n",
        "        plt.plot(coeffs_scaled['cD3'])\n",
        "        plt.title('cD3')\n",
        "\n",
        "        plt.subplot(6,1,5)\n",
        "        plt.plot(coeffs_scaled['cD2'])\n",
        "        plt.title('cD2')\n",
        "\n",
        "        plt.subplot(6,1,6)\n",
        "        plt.plot(coeffs_scaled['cD1'])\n",
        "        plt.title('cD1')\n",
        "        plt.xlabel('Index')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('wavelet_scaled.png', dpi=150)\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "    return coeffs_scaled, scaling_factors"
      ],
      "metadata": {
        "id": "HkGrLhlYOSyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unscale_coeffs(coeffs_orig, coeffs_reconstructed, scaling_factors, bits, do_plot=False):\n",
        "    coeffs_unscaled = {}\n",
        "\n",
        "    for key in coeffs_reconstructed.keys():\n",
        "        tmp_coeffs_unscaled = coeffs_reconstructed[key]/(2**bits)\n",
        "        tmp_coeffs_unscaled = tmp_coeffs_unscaled*scaling_factors[key]['scale_factor']\n",
        "        tmp_coeffs_unscaled = tmp_coeffs_unscaled + scaling_factors[key]['shift_factor']\n",
        "\n",
        "        #now replace the NaN values with 0\n",
        "        nan_inds = np.where(np.isnan(tmp_coeffs_unscaled))[0]\n",
        "        tmp_coeffs_unscaled[nan_inds] = 0\n",
        "\n",
        "        coeffs_unscaled[key] = tmp_coeffs_unscaled\n",
        "\n",
        "\n",
        "    if do_plot:\n",
        "        print('\\n\\n')\n",
        "        print('Plot of wavelet coefficients before scaling and after rescaling:')\n",
        "        plt.subplots(figsize=(16,9))\n",
        "\n",
        "        plt.subplot(6,1,1)\n",
        "        plt.plot(coeffs_orig['cA5'], label='Before Scaling')\n",
        "        plt.plot(coeffs_unscaled['cA5'], label='After Rescaling')\n",
        "        plt.legend(loc=1)\n",
        "        plt.title('cA5')\n",
        "\n",
        "        plt.subplot(6,1,2)\n",
        "        plt.plot(coeffs_orig['cD5'], label='Before Scaling')\n",
        "        plt.plot(coeffs_unscaled['cD5'], label='After Rescaling')\n",
        "        plt.legend(loc=1)\n",
        "        plt.title('cD5')\n",
        "\n",
        "        plt.subplot(6,1,3)\n",
        "        plt.plot(coeffs_orig['cD4'], label='Before Scaling')\n",
        "        plt.plot(coeffs_unscaled['cD4'], label='After Rescaling')\n",
        "        plt.legend(loc=1)\n",
        "        plt.title('cD4')\n",
        "\n",
        "        plt.subplot(6,1,4)\n",
        "        plt.plot(coeffs_orig['cD3'], label='Before Scaling')\n",
        "        plt.plot(coeffs_unscaled['cD3'], label='After Rescaling')\n",
        "        plt.legend(loc=1)\n",
        "        plt.title('cD3')\n",
        "\n",
        "        plt.subplot(6,1,5)\n",
        "        plt.plot(coeffs_orig['cD2'], label='Before Scaling')\n",
        "        plt.plot(coeffs_unscaled['cD2'], label='After Rescaling')\n",
        "        plt.legend(loc=1)\n",
        "        plt.title('cD2')\n",
        "\n",
        "        plt.subplot(6,1,6)\n",
        "        plt.plot(coeffs_orig['cD1'], label='Before Scaling')\n",
        "        plt.plot(coeffs_unscaled['cD1'], label='After Rescaling')\n",
        "        plt.legend(loc=1)\n",
        "        plt.xlabel('Index')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('wavelet_rescaled.png', dpi=150)\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "    return coeffs_unscaled"
      ],
      "metadata": {
        "id": "_exRqsM4OXPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_num_bits(orig_sig, coeffs_scaled, binary_map, scaling_factors, do_plot=True):\n",
        "    num_bits = 9\n",
        "    PRD = 0\n",
        "\n",
        "    PRD_dict = {}\n",
        "\n",
        "    if do_plot:\n",
        "        plt.subplots(figsize=(7,4))\n",
        "        t = [i/FS for i in range(NUM_SAMPLES_BLOCK)]\n",
        "        plt.plot(t, orig_sig, label='Original Signal')\n",
        "\n",
        "\n",
        "    while (num_bits >= 5) and (PRD <= MAX_PRD):\n",
        "        num_bits = num_bits-1\n",
        "\n",
        "        coeffs_quantized = do_quantization(coeffs_scaled, num_bits)\n",
        "        coeffs_unscaled = unscale_coeffs(None, coeffs_quantized, scaling_factors, num_bits)\n",
        "        data_reconstructed = wavelet_reconstruction(coeffs_unscaled, None, None)\n",
        "\n",
        "        PRD = calculate_PRD(orig_sig, data_reconstructed)\n",
        "        PRD_dict[num_bits] = PRD\n",
        "\n",
        "        if do_plot:\n",
        "            if PRD <= MAX_PRD:\n",
        "                plt.plot(t, data_reconstructed, label='Reconstructed @ %i Bits, PRD = %.2f' % (num_bits, PRD))\n",
        "\n",
        "    if PRD > MAX_PRD:\n",
        "        num_bits = num_bits+1\n",
        "        PRD = PRD_dict[num_bits]\n",
        "\n",
        "    if do_plot:\n",
        "        print('\\n\\n')\n",
        "        print('Plots of reconstructed signals vs number of bits used for quantization:')\n",
        "        plt.legend(loc='lower center', ncol=2, fontsize=9)\n",
        "        plt.tight_layout()\n",
        "        plt.xlabel('Time (seconds) $\\longrightarrow$')\n",
        "        plt.ylabel('Amplitude $\\longrightarrow$')\n",
        "        plt.xlim(0,3)\n",
        "        plt.ylim(-13,10)\n",
        "        plt.grid(True)\n",
        "\n",
        "        plt.savefig('PRD.png', dpi=150)\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "    return num_bits, PRD"
      ],
      "metadata": {
        "id": "wBn858svOJQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def combine_coefficients(coeffs, binary_map=None):\n",
        "    coeffs_combined = []\n",
        "\n",
        "    if binary_map is not None:\n",
        "        for key in coeffs.keys():\n",
        "            inds_to_keep = np.where(binary_map[key]==1)[0]\n",
        "            coeffs[key] = coeffs[key][inds_to_keep]\n",
        "    coeffs_combined.extend(coeffs['cA5'])\n",
        "    coeffs_combined.extend(coeffs['cD5'])\n",
        "    coeffs_combined.extend(coeffs['cD4'])\n",
        "    coeffs_combined.extend(coeffs['cD3'])\n",
        "    coeffs_combined.extend(coeffs['cD2'])\n",
        "    coeffs_combined.extend(coeffs['cD1'])\n",
        "\n",
        "    return coeffs_combined"
      ],
      "metadata": {
        "id": "TFkPcezrOfJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remap_coeffs(coeffs, binary_map):\n",
        "    coeffs_remapped = np.zeros(len(binary_map))*np.nan\n",
        "    inds_to_set = np.where(binary_map==1)[0]\n",
        "    coeffs_remapped[inds_to_set] = coeffs\n",
        "\n",
        "    wavelet_remapped = {}\n",
        "    counter = 0\n",
        "    wavelet_remapped['cA5'] = coeffs_remapped[counter:counter+COEFF_LENGTHS['cA5']]\n",
        "\n",
        "    counter = counter + COEFF_LENGTHS['cA5']\n",
        "    wavelet_remapped['cD5'] = coeffs_remapped[counter:counter+COEFF_LENGTHS['cD5']]\n",
        "\n",
        "    counter = counter + COEFF_LENGTHS['cD5']\n",
        "    wavelet_remapped['cD4'] = coeffs_remapped[counter:counter+COEFF_LENGTHS['cD4']]\n",
        "\n",
        "    counter = counter + COEFF_LENGTHS['cD4']\n",
        "    wavelet_remapped['cD3'] = coeffs_remapped[counter:counter+COEFF_LENGTHS['cD3']]\n",
        "\n",
        "    counter = counter + COEFF_LENGTHS['cD3']\n",
        "    wavelet_remapped['cD2'] = coeffs_remapped[counter:counter+COEFF_LENGTHS['cD2']]\n",
        "\n",
        "    counter = counter + COEFF_LENGTHS['cD2']\n",
        "    wavelet_remapped['cD1'] = coeffs_remapped[counter:counter+COEFF_LENGTHS['cD1']]\n",
        "\n",
        "    return wavelet_remapped"
      ],
      "metadata": {
        "id": "CEf4nAdhOh0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def do_quantization(coeffs, bits, do_plot=False):\n",
        "    quantized_coeffs = {}\n",
        "\n",
        "    for key in coeffs.keys():\n",
        "        sig = coeffs[key]\n",
        "        sig = sig*(2**bits-1)\n",
        "        sig = np.round(sig)\n",
        "        sig = np.array(sig).astype(int)\n",
        "\n",
        "        quantized_coeffs[key] = sig\n",
        "\n",
        "\n",
        "    if do_plot:\n",
        "        print('\\n\\n')\n",
        "        print('Plot of quantized coefficients:')\n",
        "        plt.subplots(figsize=(16,9))\n",
        "\n",
        "        plt.subplot(6,1,1)\n",
        "        plt.plot(quantized_coeffs['cA5'])\n",
        "        plt.title('cA5')\n",
        "\n",
        "        plt.subplot(6,1,2)\n",
        "        plt.plot(quantized_coeffs['cD5'])\n",
        "        plt.title('cD5')\n",
        "\n",
        "        plt.subplot(6,1,3)\n",
        "        plt.plot(quantized_coeffs['cD4'])\n",
        "        plt.title('cD4')\n",
        "\n",
        "        plt.subplot(6,1,4)\n",
        "        plt.plot(quantized_coeffs['cD3'])\n",
        "        plt.title('cD3')\n",
        "\n",
        "        plt.subplot(6,1,5)\n",
        "        plt.plot(quantized_coeffs['cD2'])\n",
        "        plt.title('cD2')\n",
        "\n",
        "        plt.subplot(6,1,6)\n",
        "        plt.plot(quantized_coeffs['cD1'])\n",
        "        plt.title('cD1')\n",
        "        plt.xlabel('Index')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('wavelet_quantized.png', dpi=150)\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "    return quantized_coeffs"
      ],
      "metadata": {
        "id": "CL0te2njOk5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compress_coefficients(coeffs, num_bits):\n",
        "\n",
        "    binary_string = ''\n",
        "\n",
        "    for coeff in coeffs:\n",
        "        binary_string = binary_string + format(coeff, '0%ib' % num_bits)\n",
        "    byte_array = []\n",
        "    for i in range(int(len(binary_string)/8)):\n",
        "        byte_tmp = binary_string[i*8:(i+1)*8]\n",
        "        byte_tmp = int(byte_tmp, 2)\n",
        "        byte_array.append(byte_tmp)\n",
        "\n",
        "    num_bits_last_byte = 8\n",
        "    if len(binary_string)%8 != 0:\n",
        "        byte_tmp = binary_string[(i+1)*8:(i+1)*8 + len(binary_string)%8]\n",
        "        num_bits_last_byte = len(byte_tmp)\n",
        "        byte_tmp = int(byte_tmp, 2)\n",
        "        byte_array.append(byte_tmp)\n",
        "\n",
        "    return byte_array, num_bits_last_byte"
      ],
      "metadata": {
        "id": "Bh9Ykd3hOoDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decompress_coefficients(coeffs_compressed, num_bits, num_bits_last_byte):\n",
        "\n",
        "    binary_string = ''\n",
        "    coeffs_len = len(coeffs_compressed)\n",
        "    for i in range(coeffs_len):\n",
        "        if i == coeffs_len-1:\n",
        "            binary_string = binary_string + format(coeffs_compressed[i], '0%ib' % num_bits_last_byte)\n",
        "        else:\n",
        "            binary_string = binary_string + format(coeffs_compressed[i], '08b')\n",
        "\n",
        "    byte_array = []\n",
        "    for i in range(int(len(binary_string)/num_bits)):\n",
        "        byte_tmp = binary_string[i*num_bits:(i+1)*num_bits]\n",
        "        byte_tmp = int(byte_tmp, 2)\n",
        "        byte_array.append(byte_tmp)\n",
        "\n",
        "\n",
        "    return byte_array"
      ],
      "metadata": {
        "id": "VJXrp-y4OsES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compress_binary_map(binary_map):\n",
        "    binary_map = copy.deepcopy(binary_map)\n",
        "    binary_map.append(int(not binary_map[-1]))\n",
        "\n",
        "\n",
        "    CURRENT_STATE = binary_map[0]\n",
        "    run_count = 0\n",
        "    binary_string = ''\n",
        "\n",
        "    #loop through each value in the binary map\n",
        "    for val in binary_map:\n",
        "\n",
        "        #if the current binary map value is the same as the previous one, just increment the run count\n",
        "        if val == CURRENT_STATE:\n",
        "            run_count = run_count + 1\n",
        "\n",
        "        #otherwise, encode the current run count\n",
        "        else:\n",
        "\n",
        "            #handle cases where run count <= 3\n",
        "            if run_count == 1:\n",
        "                binary_string_tmp = '00'\n",
        "\n",
        "            elif run_count == 2:\n",
        "                binary_string_tmp = '01'\n",
        "\n",
        "            elif run_count == 3:\n",
        "                binary_string_tmp = '10'\n",
        "\n",
        "            #otherwise, if the run count > 3\n",
        "            else:\n",
        "                #calculate the number bits required to represent the run count\n",
        "                num_bits_run_count = len(format(run_count, 'b'))\n",
        "\n",
        "                #build a binary string\n",
        "                binary_string_tmp = ''\n",
        "\n",
        "                #first bit represents that the run count > 3\n",
        "                binary_string_tmp = binary_string_tmp + '11'\n",
        "\n",
        "                #next 4 bits represent the number of bits that will define the run count\n",
        "                binary_string_tmp = binary_string_tmp + format(num_bits_run_count, '0%ib' % NUM_BITS_RUN_LEN)\n",
        "\n",
        "                #next number of bits is variable, and is the actual run count\n",
        "                #may be up to 15 bits assuming NUM_BITS_RUN_LEN=4\n",
        "                binary_string_tmp = binary_string_tmp + format(run_count, 'b')\n",
        "\n",
        "            #print(str(run_count) + ', ' + binary_string_tmp)\n",
        "            #pdb.set_trace()\n",
        "\n",
        "            #append the binary string\n",
        "            binary_string = binary_string + binary_string_tmp\n",
        "\n",
        "            #reset the run count\n",
        "            run_count = 1\n",
        "\n",
        "        #update the current state\n",
        "        CURRENT_STATE = val\n",
        "\n",
        "\n",
        "    #convert the binary string into a buffer of 8 bit bytes\n",
        "    byte_array = []\n",
        "    for i in range(int(len(binary_string)/8)):\n",
        "        byte_tmp = binary_string[i*8:(i+1)*8]\n",
        "        byte_tmp = int(byte_tmp, 2)\n",
        "        byte_array.append(byte_tmp)\n",
        "\n",
        "\n",
        "    #check if there are any remaining bits that don't divide evenly into 8\n",
        "    num_bits_last_byte = 8\n",
        "    if len(binary_string)%8 != 0:\n",
        "        byte_tmp = binary_string[(i+1)*8:(i+1)*8 + len(binary_string)%8]\n",
        "        num_bits_last_byte = len(byte_tmp)\n",
        "        byte_tmp = int(byte_tmp, 2)\n",
        "        byte_array.append(byte_tmp)\n",
        "\n",
        "\n",
        "    #return the initial state (ie, the first value in binary map), and the RLE binary map\n",
        "    return binary_map[0], byte_array, num_bits_last_byte"
      ],
      "metadata": {
        "id": "pA5eScJtOuoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decompress_binary_map(binary_map_compressed, binary_map_initial_state, num_bits_last_byte):\n",
        "\n",
        "    #first convert 8 bit numbers into a binary string\n",
        "    binary_string = ''\n",
        "\n",
        "    #convert each coefficient value to binary in 8 number of bits\n",
        "    #note that the very last value in the the binary map may not be\n",
        "    #a full 8 bits. so convert that based on num_bits_last_byte\n",
        "    binary_map_len = len(binary_map_compressed)\n",
        "    for i in range(binary_map_len):\n",
        "        if i == binary_map_len-1:\n",
        "            binary_string = binary_string + format(binary_map_compressed[i], '0%ib' % num_bits_last_byte)\n",
        "        else:\n",
        "            binary_string = binary_string + format(binary_map_compressed[i], '08b')\n",
        "\n",
        "\n",
        "    #define a state machine that loops through each entry in the binary map and\n",
        "    #creates the uncompressed representation.\n",
        "    READ_HEADER = 0\n",
        "    READ_NUM_BITS = 1\n",
        "    READ_RUN_LEN = 2\n",
        "    state = READ_HEADER\n",
        "\n",
        "    run_type = binary_map_initial_state\n",
        "    header = ''\n",
        "    binary_array = np.array([])\n",
        "\n",
        "\n",
        "    #loop through each value in the binary map\n",
        "    for val in binary_string:\n",
        "\n",
        "        #read the header\n",
        "        if state == READ_HEADER:\n",
        "            header = header + val\n",
        "\n",
        "            if len(header) == 2:\n",
        "                #run count 1\n",
        "                if header == '00':\n",
        "                    binary_array = np.concatenate((binary_array, np.ones(1)*run_type))\n",
        "                    run_type = int(not run_type)\n",
        "                    state = READ_HEADER\n",
        "\n",
        "                #run count 2\n",
        "                if header == '01':\n",
        "                    binary_array = np.concatenate((binary_array, np.ones(2)*run_type))\n",
        "                    run_type = int(not run_type)\n",
        "                    state = READ_HEADER\n",
        "\n",
        "                #run count 3\n",
        "                if header == '10':\n",
        "                    binary_array = np.concatenate((binary_array, np.ones(3)*run_type))\n",
        "                    run_type = int(not run_type)\n",
        "                    state = READ_HEADER\n",
        "\n",
        "                #run count > 3\n",
        "                if header == '11':\n",
        "                    state = READ_NUM_BITS\n",
        "                    num_bits = ''\n",
        "\n",
        "\n",
        "                #reset header\n",
        "                header = ''\n",
        "\n",
        "            continue\n",
        "\n",
        "        #read number of bits\n",
        "        if state == READ_NUM_BITS:\n",
        "\n",
        "\n",
        "            num_bits = num_bits + val\n",
        "\n",
        "            if len(num_bits) == 4:\n",
        "                num_bits_run_len = int(num_bits, 2)\n",
        "                run_len = ''\n",
        "\n",
        "                state = READ_RUN_LEN\n",
        "\n",
        "            continue\n",
        "\n",
        "\n",
        "        #read run length\n",
        "        if state == READ_RUN_LEN:\n",
        "            run_len = run_len + val\n",
        "\n",
        "            if len(run_len) == num_bits_run_len:\n",
        "                run_len = int(run_len, 2)\n",
        "                binary_array = np.concatenate((binary_array, np.ones(run_len)*run_type))\n",
        "                run_type = int(not run_type)\n",
        "                state = READ_HEADER\n",
        "\n",
        "            continue\n",
        "\n",
        "\n",
        "    return binary_array"
      ],
      "metadata": {
        "id": "W7qtjdVNOyg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_compression_ratio(coeffs_compressed, scaling_factors, num_bits, binary_map_compressed, binary_map_initial_state):\n",
        "\n",
        "    #each value in the compressed coefficients is 8 bits\n",
        "    num_bits_compressed = len(coeffs_compressed)*8\n",
        "\n",
        "    #the number of bits in the last byte of the compressed coeffs is 8\n",
        "    #and another 8 bits for the last byte of the compressed binary map\n",
        "    num_bits_compressed = num_bits_compressed + 16\n",
        "\n",
        "    #each set of scaling factors has 2 float values, and each float value is 32 bits\n",
        "    num_bits_compressed = num_bits_compressed + len(scaling_factors)*2*32\n",
        "\n",
        "    #the number of bits corresponds to one byte\n",
        "    num_bits_compressed = num_bits_compressed + 8\n",
        "\n",
        "    #each value in the compressed binary map is 8 bits\n",
        "    num_bits_compressed = num_bits_compressed + len(binary_map_compressed)*8\n",
        "\n",
        "    #the initial state of the binary map is just one bit but assume it's stored as a byte\n",
        "    num_bits_compressed = num_bits_compressed + 8\n",
        "\n",
        "    #each of the original data are 16 bits\n",
        "    num_bits_uncompressed = NUM_SAMPLES_BLOCK*16\n",
        "\n",
        "    #get the compression ratio\n",
        "    compression_ratio = num_bits_uncompressed/num_bits_compressed\n",
        "\n",
        "    return compression_ratio"
      ],
      "metadata": {
        "id": "P5UdGz_vO3Es"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def do_detrend(sig, do_plot=True):\n",
        "    detrended = detrend(sig)\n",
        "\n",
        "    if do_plot:\n",
        "        print('\\n\\n')\n",
        "        print('Original and detrended signal:')\n",
        "\n",
        "        t = [i/FS for i in range(NUM_SAMPLES_BLOCK)]\n",
        "        plt.subplots(figsize=(16,9))\n",
        "        plt.plot(t, sig, label='Original Signal')\n",
        "        plt.plot(t, detrended, label='Detrended Signal')\n",
        "        plt.xlabel('Time (seconds)')\n",
        "        plt.ylabel('Amplitude (mV)')\n",
        "        plt.tight_layout()\n",
        "        plt.legend(loc=1)\n",
        "        axes = plt.gca()\n",
        "        axes.set_xlim((17, 21.5))\n",
        "        plt.savefig('detrending.png', dpi=150)\n",
        "        plt.show()\n",
        "\n",
        "    return detrended"
      ],
      "metadata": {
        "id": "4WLKubDyO5pF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def energy(sig):\n",
        "    return np.sum(sig**2)"
      ],
      "metadata": {
        "id": "21sKxNduO71J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_PRD(orig_sig, reconstructed_sig):\n",
        "    num = np.sum((orig_sig - reconstructed_sig)**2)\n",
        "    den = np.sum(orig_sig**2)\n",
        "\n",
        "    PRD = np.sqrt(num/den)\n",
        "\n",
        "    return PRD"
      ],
      "metadata": {
        "id": "abZ5-q9UO-CK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('Activity Extended.csv')\n",
        "df = df[df['Activity'] == 'Left 45'][:].reset_index(drop=True)\n",
        "df = df.drop(['Activity','Unnamed: 0','Ax','Ay','Az','Gx','Gy'],axis=1)\n",
        "df"
      ],
      "metadata": {
        "id": "SChIsvnES-69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = int(len(df['Gz'])/NUM_SAMPLES_BLOCK)\n",
        "\n",
        "#calculate the average CR and average PRD\n",
        "CR_avg = 0\n",
        "PRD_avg = 0\n",
        "\n",
        "#plot stuff\n",
        "do_plot = True\n",
        "\n",
        "#loop over the data in 10 second chunks\n",
        "for i in range(N):\n",
        "    data = df.iloc[i*NUM_SAMPLES_BLOCK:(i+1)*NUM_SAMPLES_BLOCK, 0].values\n",
        "\n",
        "    #detrend the signal as a preprocessing step to remove unecessary information\n",
        "    data = do_detrend(data, (i==1))\n",
        "\n",
        "    #do wavelet decomposition\n",
        "    coeffs = wavelet_decomposition(data)\n",
        "\n",
        "    #threshold the coefficients such that 95% of the signal energy is retained\n",
        "    #return nonzero thresholded coefficients, along with a binary map of zero/nonzero values\n",
        "    #and a list of how many nonzero values were in each set of coefficients\n",
        "    coeffs_thresholded, binary_map = threshold_energy(coeffs, do_plot=True)#(i==1))\n",
        "\n",
        "    #scale each set of wavelet coefficients between zero and one\n",
        "    #keep track of the scaling factors to re-scale to the original range later\n",
        "    coeffs_scaled, scaling_factors = scale_coeffs(coeffs_thresholded, do_plot=True)#(i==1))\n",
        "\n",
        "    #quantize the coefficients. choose the number of bits to quantize based on the PRD\n",
        "    num_bits, PRD_tmp = calculate_num_bits(data, coeffs_scaled, binary_map, scaling_factors, do_plot=True)#(i==1))\n",
        "    PRD_avg = PRD_avg + PRD_tmp\n",
        "\n",
        "    #get quantized coefficients\n",
        "    coeffs_quantized = do_quantization(coeffs_scaled, num_bits, do_plot=True)#(i==1))\n",
        "\n",
        "    #combine all the quantized coefficients into a single array for compression\n",
        "    #also combine all the binary maps into a single array for compression\n",
        "    coeffs_quantized_combined = combine_coefficients(coeffs_quantized, binary_map)\n",
        "    binary_map_combined = combine_coefficients(binary_map)\n",
        "\n",
        "    #compress the quantized coefficients\n",
        "    coeffs_quantized_compressed, num_bits_last_byte_coeffs = compress_coefficients(coeffs_quantized_combined, num_bits)\n",
        "\n",
        "    #compress the binary map\n",
        "    binary_map_initial_state, binary_map_compressed, num_bits_last_byte_binary_map = compress_binary_map(binary_map_combined)\n",
        "\n",
        "\n",
        "    #calculate the compression ratio for this transmission\n",
        "    CR_tmp = calculate_compression_ratio(coeffs_quantized_compressed, scaling_factors, num_bits, binary_map_compressed, binary_map_initial_state)\n",
        "    CR_avg = CR_avg + CR_tmp\n",
        "\n",
        "    #decompress the binary map\n",
        "    binary_map_decompressed = decompress_binary_map(binary_map_compressed, binary_map_initial_state, num_bits_last_byte_binary_map)\n",
        "\n",
        "    #decompress the coefficients\n",
        "    coeffs_decompressed = decompress_coefficients(coeffs_quantized_compressed, num_bits, num_bits_last_byte_coeffs)\n",
        "\n",
        "    #remap all the coefficients back to their original wavelet decompositions\n",
        "    coeffs_reconstructed = remap_coeffs(coeffs_decompressed, binary_map_decompressed)\n",
        "\n",
        "    #rescale the coefficients\n",
        "    coeffs_unscaled = unscale_coeffs(coeffs, coeffs_reconstructed, scaling_factors, num_bits, do_plot=True)#(i==1))\n",
        "\n",
        "    #do the inverse dwt\n",
        "    data_reconstructed = wavelet_reconstruction(coeffs_unscaled, data, CR_tmp, do_plot=True)#(i==1))\n",
        "\n",
        "\n",
        "\n",
        "#calculate the average compression ratio and PRD\n",
        "CR_avg = CR_avg/N\n",
        "PRD_avg = PRD_avg/N\n",
        "print('Average compression ratio: %.1f' % CR_avg)\n",
        "print('Average PRD: %.3f' % PRD_avg)"
      ],
      "metadata": {
        "id": "ltqYMUrDPBQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L9K3u1ofOJTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wFpMPfFLN9LO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uH8IoceVN9OZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1yAnAOy-N9Q2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bAcYDZGFN9S_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}